#!/usr/bin/env python3
"""
Teste de consumo de tokens em conversa longa com cliente
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agent_langgraph_simple import run_agent_langgraph

def simular_conversa_longa():
    """Simula uma conversa longa e realista com cliente de supermercado"""
    
    print("ğŸ§ª Simulando CONVERSA LONGA com cliente (modo econÃ´mico)")
    print("=" * 70)
    
    telefone = "558587520060"  # Usar o mesmo telefone do exemplo real
    
    # SimulaÃ§Ã£o de uma conversa real longa com idas e vindas
    conversa = [
        {
            "role": "user", 
            "content": "Oi Ana, boa noite! Vim aqui pedir umas coisinhas para minha vovÃ³ que tÃ¡ de visita em casa. Preciso de coisas agora porque amanhÃ£ nÃ£o sei se eu dou conta, tÃ¡ tudo uma correria aqui. Pode me ajudar?"
        },
        {
            "role": "user", 
            "content": "Quero arroz, mas aquele agulhinha que vocÃªs tÃªm. Ã‰ 5kg ou maior? E tambÃ©m preciso de pÃ£o, mas o Pullman que ele gosta. Ah, e leite condensado tambÃ©m para fazer um doce."
        },
        {
            "role": "user", 
            "content": "Esqueci de falar do leite condensado. Ã‰ daquele de lata mesmo, o tradicional. Qual marca vocÃªs tÃªm? Tem da NestlÃ© ou da MoÃ§a?"
        },
        {
            "role": "user", 
            "content": "Pera aÃ­ Ana, tira esse arroz agulhinha que eu falei. Meu avÃ´ nÃ£o gosta muito desse. Coloca no lugar o arroz parboilizado mesmo, aquele branquinho. E quanto ao leite condensado, coloca o da NestlÃ© de 395g."
        },
        {
            "role": "user", 
            "content": "Ah, e tira o pÃ£o Pullman tambÃ©m! Esqueci que ele tÃ¡ de dieta. Coloca o pÃ£o integral de forma, aquele mesmo. Quantos gramas tem esse aÃ­?"
        },
        {
            "role": "user", 
            "content": "Ã“timo! Agora me fala uma coisa: vocÃªs tÃªm mortadela? Mas nÃ£o aquela com olho que ele nÃ£o gosta. Ã‰ a sem olho, sabe? Aquele pedaÃ§o inteiro que a gente corta em fatias."
        },
        {
            "role": "user", 
            "content": "Perfeito! E quanto Ã© tudo isso que jÃ¡ temos aÃ­? SÃ³ para eu ir me organizando. DÃ¡ um total aÃ­ pra mim ver se preciso tirar ou colocar mais alguma coisa."
        },
        {
            "role": "user", 
            "content": "Espera Ana! Acabei de lembrar que preciso de mais uma coisa. Meu vÃ´ gosta de tomar cafÃ© da tarde com aquele biscoito cream cracker. VocÃªs tÃªm? Ã‰ daquele de pacote, sabe? Qual marca vocÃªs tÃªm?" 
        },
        {
            "role": "user", 
            "content": "TÃ¡ bom, coloca o cream cracker mesmo. Agora Ã© sÃ³ isso mesmo! Qual Ã© o total final? E me fala: Ã© melhor eu retirar na loja ou vocÃªs entregam em casa? Qual Ã© mais rÃ¡pido?"
        },
        {
            "role": "user", 
            "content": "EntÃ£o coloca para entrega em casa. Me confirma tudo de novo pra eu ter certeza: arroz parboilizado 5kg, pÃ£o integral de forma, leite condensado NestlÃ© 395g, mortadela sem olho e cream cracker. EstÃ¡ tudo certo?"
        }
    ]
    
    print(f"ğŸ“± Cliente: {telefone}")
    print(f"ğŸ“ Simulando conversa com {len(conversa)} trocas de mensagens")
    print(f"ğŸ¯ Modo: ECONÃ”MICO (respostas curtas)")
    print()
    
    total_tokens_estimado = 0
    total_caracteres = 0
    
    for i, mensagem in enumerate(conversa, 1):
        print(f"ğŸ”„ Mensagem {i}/{len(conversa)}")
        print(f"ğŸ‘¤ Cliente: {mensagem['content'][:80]}...")
        
        try:
            resultado = run_agent_langgraph(
                telefone=telefone,
                mensagem=mensagem['content']
            )
            
            resposta = resultado.get('output', 'Sem resposta')
            
            # AnÃ¡lise da resposta
            caracteres = len(resposta)
            palavras = len(resposta.split())
            tokens_estimados = caracteres // 4  # Estimativa conservadora
            
            print(f"ğŸ¤– Ana: {resposta[:80]}...")
            print(f"ğŸ“Š MÃ©tricas: {palavras} palavras, {caracteres} caracteres, ~{tokens_estimados} tokens")
            print()
            
            total_tokens_estimado += tokens_estimados
            total_caracteres += caracteres
            
            if resultado.get('error'):
                print(f"âš ï¸  Erro: {resultado['error']}")
                break
                
        except Exception as e:
            print(f"âŒ Erro ao processar mensagem {i}: {e}")
            break
    
    print("=" * 70)
    print("ğŸ“ˆ RESUMO DA CONVERSA:")
    print(f"   Total de mensagens: {len(conversa)}")
    print(f"   Total de caracteres: {total_caracteres:,}")
    print(f"   Total estimado de tokens: {total_tokens_estimado:,}")
    print()
    
    # CÃ¡lculo de custo com GPT-5-mini
    custo_entrada = (total_tokens_estimado * 0.8) * 0.00000025  # 80% para entrada
    custo_saida = (total_tokens_estimado * 0.2) * 0.00000200     # 20% para saÃ­da
    custo_total = custo_entrada + custo_saida
    
    print("ğŸ’° CUSTO ESTIMADO (GPT-5-mini):")
    print(f"   Entrada: US$ {custo_entrada:.6f}")
    print(f"   SaÃ­da: US$ {custo_saida:.6f}")
    print(f"   Total: US$ {custo_total:.6f}")
    print(f"   Em Reais: R$ {custo_total * 6:.4f}")
    print()
    
    # ProjeÃ§Ã£o mensal
    print("ğŸ“Š PROJEÃ‡ÃƒO MENSAL (50 conversas longas/dia):")
    custo_mensal = custo_total * 50 * 30
    print(f"   Custo mensal: US$ {custo_mensal:.2f}")
    print(f"   Custo mensal: R$ {custo_mensal * 6:.2f}")
    
    # ComparaÃ§Ã£o com modo nÃ£o econÃ´mico
    print()
    print("ğŸ” COMPARAÃ‡ÃƒO:")
    print(f"   Com modo econÃ´mico: R$ {custo_mensal * 6:.2f}/mÃªs")
    print(f"   Sem modo econÃ´mico: R$ {custo_mensal * 6 * 2:.2f}/mÃªs")
    print(f"   Economia mensal: R$ {custo_mensal * 6:.2f}")

if __name__ == "__main__":
    simular_conversa_longa()